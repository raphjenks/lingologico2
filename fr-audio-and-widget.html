<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <title>Speech Recognition with Audio Meter</title>
</head>
<body>
  <button id="button" onclick="toggleStartStop()">Click to Start</button>
  <canvas id="waveCanvas" width="800" height="400"></canvas>

  <script type="text/javascript">
    var recognizing = false;
    var recognition;
    var isRecording = false;
    var audioContext;
    var analyserNode;
    var pcmData;

    function reset() {
      recognizing = false;
      isRecording = false;
      button.innerHTML = "Click to Start";
    }

    async function initializeAudio() {
      const stream = await navigator.mediaDevices.getUserMedia({ audio: true, video: false });
      audioContext = new AudioContext();
      const mediaStreamAudioSourceNode = audioContext.createMediaStreamSource(stream);
      analyserNode = audioContext.createAnalyser();
      mediaStreamAudioSourceNode.connect(analyserNode);
      pcmData = new Float32Array(analyserNode.fftSize);

      const canvas = document.getElementById("waveCanvas");
      const ctx = canvas.getContext("2d");

      const onFrame = () => {
        if (isRecording) {
          analyserNode.getFloatTimeDomainData(pcmData);
          drawWaveform(pcmData);
        }
        window.requestAnimationFrame(onFrame);
      };

      const drawWaveform = (pcmData) => {
        ctx.clearRect(0, 0, canvas.width, canvas.height);
        ctx.beginPath();
        for (let i = 0; i < pcmData.length; i++) {
          const x = i * (canvas.width / pcmData.length);
          const y = (pcmData[i] + 1) * canvas.height / 2;
          i === 0 ? ctx.moveTo(x, y) : ctx.lineTo(x, y);
        }
        ctx.stroke();
      };

      window.requestAnimationFrame(onFrame);
    }

    if ('SpeechRecognition' in window || 'webkitSpeechRecognition' in window) {
      recognition = new (window.SpeechRecognition || window.webkitSpeechRecognition)();
      recognition.continuous = true;
      recognition.lang = 'fr-FR';
      recognition.interimResults = true;
      reset();

      recognition.onstart = function() {
        sendMicStatus(true);
        isRecording = true;
        button.innerHTML = "Click to Stop";
      };

      recognition.onend = function() {
        sendMicStatus(false);
        isRecording = false;
        button.innerHTML = "Click to Start";
        if (isRecording) {
          startRecognition();
        }
      };

      recognition.onresult = function(event) {
        var interim = "";
        for (var i = 0; i < event.results.length; ++i) {
          interim += event.results[i][0].transcript;
        }
        var transcription = { interim: interim };
        window.parent.postMessage(transcription, '*');
      };

      window.addEventListener('message', function(event) {
        if (event.data === 'start') {
          startRecognition();
        } else if (event.data === 'stop') {
          stopRecognition();
        } else if (event.data === 'interrupt') {
          interruptRecognition();
        } else if (event.data === 'abort') {
          abortRecognition();
        }
      });

      initializeAudio();
    } else {
      console.log('Speech recognition not supported');
    }

    function toggleStartStop() {
      if (recognizing) {
        stopRecognition();
      } else {
        startRecognition();
      }
    }

    function startRecognition() {
      if (!recognizing) {
        recognition.start();
        recognizing = true;
        isRecording = true;
        button.innerHTML = "Click to Stop";
      }
    }

    function stopRecognition() {
      if (recognizing) {
        recognition.stop();
        recognizing = false;
        isRecording = false;
        button.innerHTML = "Click to Start";
        sendMicStatus(isRecording);
      }
    }

    function abortRecognition() {
      if (recognizing) {
        recognition.abort();
        recognizing = false;
        is
