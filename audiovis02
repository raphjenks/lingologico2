<button id="button" onclick="toggleStartStop()">Click to Start</button>

<script type="text/javascript">
  var recognizing;
  var recognition;
  var isRecording = false; 

  function reset() {
    recognizing = false;
    isRecording = false;
    button.innerHTML = "Click to Start";
  }

  if ('SpeechRecognition' in window || 'webkitSpeechRecognition' in window) {
    recognition = new (window.SpeechRecognition || window.webkitSpeechRecognition)();
    recognition.continuous = true;
    recognition.lang = 'fr-FR';
    recognition.interimResults = true;
    reset();

    recognition.onstart = function() {
      sendMicStatus(true);
      isRecording = true;
      button.innerHTML = "Click to Stop";
    };

    recognition.onend = function() {
      sendMicStatus(false);
      isRecording = false;
      button.innerHTML = "Click to Start";
      if (isRecording) {
        startRecognition();
      }
    };

    recognition.onresult = function(event) {
      var interim = "";
      for (var i = 0; i < event.results.length; ++i) {
        interim += event.results[i][0].transcript;
      }

      var transcription = {
        interim: interim
      };
      window.parent.postMessage(transcription, '*');
    };

    window.addEventListener('message', function(event) {
      if (event.data === 'start') {
        startRecognition();
      } else if (event.data === 'stop') {
        stopRecognition();
      } else if (event.data === 'interrupt') {
        interruptRecognition();
      } else if (event.data === 'abort') {
        abortRecognition();
      }
    });
  } else {
    console.log('Speech recognition not supported');
  }

  function toggleStartStop() {
    if (recognizing) {
      stopRecognition();
    } else {
      startRecognition();
    }
  }

  function startRecognition() {
    if (!recognizing) {
      recognition.start();
      recognizing = true;
      isRecording = true; 
      button.innerHTML = "Click to Stop";
    }
  }

  function stopRecognition() {
    if (recognizing) {
      recognition.stop();
      recognizing = false;
      isRecording = false; 
      button.innerHTML = "Click to Start";
      sendMicStatus(isRecording);
    }
  }

  function abortRecognition() {
    if (recognizing) {
      recognition.abort();
      recognizing = false;
      isRecording = false; 
      button.innerHTML = "Click to Start";
      sendMicStatus(isRecording);
    }
  }

  function interruptRecognition() {
    if (recognizing) {
      recognition.abort();
      reset();
      setTimeout(function() {
        startRecognition(); 
      },50); 
    }
  }

  function sendMicStatus(isRecording) {
    var micStatus = {
      isRecording: isRecording
    };
    window.parent.postMessage(micStatus, '*');
  }
</script>

    <canvas id="waveCanvas" width="378" height="50"></canvas>

    <script>
        let audioContext = null, mediaStreamAudioSourceNode = null, analyserNode = null, animationFrameId = null;
        let pcmData, canvas, ctx;

        // Function to start visualizer
        async function startVisualizer() {
            try {
                if (!audioContext) {
                    const stream = await navigator.mediaDevices.getUserMedia({ audio: true, video: false });
                    audioContext = new AudioContext();
                    mediaStreamAudioSourceNode = audioContext.createMediaStreamSource(stream);
                    analyserNode = audioContext.createAnalyser();

                    mediaStreamAudioSourceNode.connect(analyserNode);
                }

                // Show canvas
                canvas = document.getElementById("waveCanvas");
                canvas.style.display = "block";
                ctx = canvas.getContext("2d");
                
                pcmData = new Float32Array(analyserNode.fftSize);
                animationFrameId = window.requestAnimationFrame(onFrame);
            } catch (error) {
                console.error("Error initializing audio:", error);
            }
        }

        // Function to stop visualizer
        function stopVisualizer() {
            // Hide canvas
            if (canvas) {
                canvas.style.display = "none";
            }

            // Cancel animation frame
            if (animationFrameId !== null) {
                window.cancelAnimationFrame(animationFrameId);
                animationFrameId = null;
            }

            // Optional: Disconnect nodes and close AudioContext
            if (mediaStreamAudioSourceNode && analyserNode) {
                mediaStreamAudioSourceNode.disconnect(analyserNode);
            }
            if (audioContext) {
                audioContext.close().then(() => {
                    audioContext = null;
                });
            }
        }

        const onFrame = () => {
            analyserNode.getFloatTimeDomainData(pcmData);
            drawWaveform(pcmData);
            animationFrameId = window.requestAnimationFrame(onFrame);
        };

        const drawWaveform = (pcmData) => {
            ctx.clearRect(0, 0, canvas.width, canvas.height);
            ctx.beginPath();
            for (let i = 0; i < pcmData.length; i++) {
                const x = i * (canvas.width / pcmData.length);
                const y = (pcmData[i] + 1) * canvas.height / 2;
                i === 0 ? ctx.moveTo(x, y) : ctx.lineTo(x, y);
            }
            ctx.stroke();
        }
    </script>

    <script>
        // Example usage:
        // To start the visualizer, run: startVisualizer();
        // To stop the visualizer, run: stopVisualizer();
    </script>
</body>
</html>
